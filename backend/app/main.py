from fastapi import FastAPI, HTTPException
from pydantic import BaseModel
from typing import Optional
import uvicorn
from urllib.parse import urlparse

# Kendi servislerini import et
from services.prediction_model import PredictionModel
from services.preprocessing import TextPreprocessingService
from services.scraper import NewsScraperService

app = FastAPI(title="Sahte Haber Tespit API", version="2.0")

# --- SERVÄ°SLERÄ° BAÅžLAT ---
print("ðŸš€ Servisler baÅŸlatÄ±lÄ±yor...")
ai_model = PredictionModel()
cleaner = TextPreprocessingService()
scraper = NewsScraperService()

# --- GÃœVENÄ°LÄ°R KAYNAKLAR (WHITELIST) ---
# Bu siteler "YalancÄ± Ã‡oban" deÄŸildir, direk geÃ§iÅŸ izni verilir.
TRUSTED_DOMAINS = [
    "trthaber.com", "hurriyet.com.tr", "aa.com.tr", "cnnturk.com",
    "ntv.com.tr", "haberturk.com", "sozcu.com.tr", "cumhuriyet.com.tr",
    "fanatik.com.tr", "beinsports.com.tr", "sabah.com.tr", "bbc.com",
    "milliyet.com.tr", "onedio.com", "webtekno.com", "shiftdelete.net"
]


# --- REQUEST & RESPONSE MODELLERÄ° ---
class AnalyzeRequest(BaseModel):
    text: Optional[str] = None
    url: Optional[str] = None


class AnalyzeResponse(BaseModel):
    durum: str  # "GERÃ‡EK HABER" / "SAHTE HABER"
    renk: str  # "green" / "red"
    guven_skoru: float  # 0.0 - 100.0
    ozet: str
    kaynak_turu: str  # "Yapay Zeka" veya "Whitelist"


@app.post("/analyze", response_model=AnalyzeResponse)
async def analyze_news(request: AnalyzeRequest):
    ham_metin = ""
    is_trusted_source = False
    trusted_source_name = ""

    # --- SENARYO 1: URL ANALÄ°ZÄ° ---
    if request.url:
        try:
            # 1. Domain KontrolÃ¼ (Whitelist)
            parsed_url = urlparse(request.url)
            domain = parsed_url.netloc.replace("www.", "")

            # Domainin iÃ§inde trusted listesinden biri geÃ§iyor mu?
            for trusted in TRUSTED_DOMAINS:
                if trusted in domain:
                    is_trusted_source = True
                    trusted_source_name = trusted
                    break

            # EÄŸer gÃ¼venilirse hemen dÃ¶n (AI'yÄ± yorma)
            if is_trusted_source:
                return AnalyzeResponse(
                    durum="GERÃ‡EK HABER",
                    renk="green",
                    guven_skoru=100.0,
                    ozet=f"Bu haber, doÄŸrulanmÄ±ÅŸ gÃ¼venilir kaynaklar listesinde bulunan ({trusted_source_name}) sitesinden alÄ±nmÄ±ÅŸtÄ±r.",
                    kaynak_turu="GÃ¼venilir Kaynak (Whitelist)"
                )

            # GÃ¼venilir deÄŸilse siteye git ve veriyi Ã§ek
            ham_metin = scraper.scrape_url(request.url)
            if not ham_metin or len(ham_metin) < 50:
                raise HTTPException(status_code=400, detail="Haber iÃ§eriÄŸi Ã§ekilemedi veya Ã§ok kÄ±sa.")

        except Exception as e:
            # URL hatasÄ± olursa, kullanÄ±cÄ±ya bildir
            raise HTTPException(status_code=400, detail=f"URL HatasÄ±: {str(e)}")

    # --- SENARYO 2: TEXT ANALÄ°ZÄ° ---
    elif request.text:
        ham_metin = request.text
        if len(ham_metin) < 10:
            raise HTTPException(status_code=400, detail="LÃ¼tfen daha uzun bir metin giriniz.")
    else:
        raise HTTPException(status_code=400, detail="LÃ¼tfen bir URL veya Metin (text) giriniz.")

    # --- YAPAY ZEKA SÃœRECÄ° (Sadece Whitelist'e takÄ±lmayanlar buraya gelir) ---

    # 1. Temizleme (Preprocessing) - Ã‡OK Ã–NEMLÄ°
    # Bunu yapmazsan model "Åžok" kelimesini tanÄ±maz Ã§Ã¼nkÃ¼ eÄŸitimde "ÅŸok" olarak Ã¶ÄŸrendi.
    temiz_metin = cleaner.clean_text(ham_metin)

    # 2. Tahmin
    sonuc = ai_model.predict(temiz_metin)

    # 3. CevabÄ± HazÄ±rla
    if sonuc["is_fake"]:
        durum_mesaji = "SAHTE HABER"
        renk_kodu = "red"
    else:
        durum_mesaji = "GERÃ‡EK HABER"
        renk_kodu = "green"

    # Ã–zetleme (Metnin ilk 200 karakteri)
    ozet_metin = ham_metin[:200] + "..." if len(ham_metin) > 200 else ham_metin

    return AnalyzeResponse(
        durum=durum_mesaji,
        renk=renk_kodu,
        guven_skoru=sonuc["confidence_score"],
        ozet=ozet_metin,
        kaynak_turu="Yapay Zeka Analizi"
    )


if __name__ == "__main__":
    uvicorn.run("main:app", host="127.0.0.1", port=8000, reload=True)